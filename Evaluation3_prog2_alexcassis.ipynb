{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEnTFH0okJzdaG8VqSgmEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexcassis/movie_recomendations/blob/master/Evaluation3_prog2_alexcassis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation de PySpark (N'oubliez pas de charger le fichier AAPL.csv)"
      ],
      "metadata": {
        "id": "_43L0XyxsnGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RTI8a3k5sKW5",
        "outputId": "f4dfadd1-c417-4665-9e34-92b81f0a68df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=8126acadde421ec9238c31875e1d785f9a344305161fdd767eb23dcb7347be89\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création de la session Spark et importation du fichier AAPL.csv qui a été téléchargé dans le répertoire Colab."
      ],
      "metadata": {
        "id": "fNx-y9Tpsmbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Analyse transactions en bourse pour AAPL\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "aaplStockData = spark.read \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(\"AAPL.csv\")\n",
        "\n",
        "aaplStockData.createOrReplaceTempView(\"aapl_csv\")\n"
      ],
      "metadata": {
        "id": "tevRzhEPsc1V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Liste des dates de transaction, ouverture et fermeture de la valeur de l’action"
      ],
      "metadata": {
        "id": "jz6ccZobtFcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = spark.sql(\"SELECT Date, Open, Close FROM aapl_csv\")\n",
        "query1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "COw4YyQ1tFLW",
        "outputId": "4ca0a685-c5e0-4249-df25-f71ebb02dc05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+----------+\n",
            "|               Date|      Open|     Close|\n",
            "+-------------------+----------+----------+\n",
            "|2014-09-29 00:00:00|100.589996| 99.620003|\n",
            "|2014-10-06 00:00:00| 99.949997|100.730003|\n",
            "|2014-10-13 00:00:00|101.330002| 97.669998|\n",
            "|2014-10-20 00:00:00|     98.32|105.220001|\n",
            "|2014-10-27 00:00:00|104.849998|     108.0|\n",
            "|2014-11-03 00:00:00|108.220001|109.010002|\n",
            "|2014-11-10 00:00:00|109.019997|    114.18|\n",
            "|2014-11-17 00:00:00|114.269997|116.470001|\n",
            "|2014-11-24 00:00:00|116.849998|    118.93|\n",
            "|2014-12-01 00:00:00|118.809998|     115.0|\n",
            "|2014-12-08 00:00:00|114.099998|109.730003|\n",
            "|2014-12-15 00:00:00|110.699997|111.779999|\n",
            "|2014-12-22 00:00:00|112.160004|113.989998|\n",
            "|2014-12-29 00:00:00|113.790001|109.330002|\n",
            "|2015-01-05 00:00:00|108.290001|112.010002|\n",
            "|2015-01-12 00:00:00|112.599998|105.989998|\n",
            "|2015-01-19 00:00:00|107.839996|112.980003|\n",
            "|2015-01-26 00:00:00|113.739998|117.160004|\n",
            "|2015-02-02 00:00:00|118.050003|    118.93|\n",
            "|2015-02-09 00:00:00|118.550003|127.080002|\n",
            "+-------------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Liste des dates de transaction avec la différence entre fermeture et ouverture"
      ],
      "metadata": {
        "id": "6yfnRrMNtMpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = spark.sql(\"SELECT Date, (Close - Open) AS Difference FROM aapl_csv\")\n",
        "query2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nJYX3_y2tOzW",
        "outputId": "b874210a-6598-4d9a-8cea-0c33826353d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+\n",
            "|               Date|         Difference|\n",
            "+-------------------+-------------------+\n",
            "|2014-09-29 00:00:00|-0.9699930000000023|\n",
            "|2014-10-06 00:00:00| 0.7800060000000002|\n",
            "|2014-10-13 00:00:00|-3.6600039999999865|\n",
            "|2014-10-20 00:00:00|  6.900001000000003|\n",
            "|2014-10-27 00:00:00| 3.1500020000000006|\n",
            "|2014-11-03 00:00:00| 0.7900010000000037|\n",
            "|2014-11-10 00:00:00|  5.160003000000003|\n",
            "|2014-11-17 00:00:00| 2.2000039999999927|\n",
            "|2014-11-24 00:00:00| 2.0800020000000075|\n",
            "|2014-12-01 00:00:00| -3.809997999999993|\n",
            "|2014-12-08 00:00:00| -4.369995000000003|\n",
            "|2014-12-15 00:00:00| 1.0800020000000075|\n",
            "|2014-12-22 00:00:00| 1.8299939999999992|\n",
            "|2014-12-29 00:00:00|-4.4599990000000105|\n",
            "|2015-01-05 00:00:00| 3.7200009999999963|\n",
            "|2015-01-12 00:00:00| -6.609999999999999|\n",
            "|2015-01-19 00:00:00|  5.140006999999997|\n",
            "|2015-01-26 00:00:00| 3.4200060000000008|\n",
            "|2015-02-02 00:00:00|  0.879997000000003|\n",
            "|2015-02-09 00:00:00|   8.52999899999999|\n",
            "+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max et Min des volumes"
      ],
      "metadata": {
        "id": "0agHZUIGtVRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = spark.sql(\"SELECT MAX(Volume) AS MaxVolume, MIN(Volume) AS MinVolume FROM aapl_csv\")\n",
        "query3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Cbd3mGM3tVxn",
        "outputId": "7d2e370a-24dd-4033-ae3a-c2d9c39a3abf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|MaxVolume|MinVolume|\n",
            "+---------+---------+\n",
            "|500363000| 38398505|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moyenne des valeurs d’ouverture par années"
      ],
      "metadata": {
        "id": "E4LkgXHFtXie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = spark.sql(\"\"\"\n",
        "  SELECT YEAR(Date) AS Year, AVG(Open) AS AvgOpen\n",
        "  FROM aapl_csv\n",
        "  GROUP BY YEAR(Date)\n",
        "  ORDER BY YEAR(Date)\n",
        "\"\"\")\n",
        "query4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BXn5rCWItauP",
        "outputId": "2e620d08-2a37-4141-b5d2-ef7a6e09a5f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+\n",
            "|Year|           AvgOpen|\n",
            "+----+------------------+\n",
            "|2014|108.78285600000001|\n",
            "|2015|120.08519211538461|\n",
            "|2016|104.27115398076923|\n",
            "|2017|149.64134611538464|\n",
            "|2018|171.75464521428572|\n",
            "+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Somme des volumes par mois"
      ],
      "metadata": {
        "id": "4RIVcuEktcm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query5 = spark.sql(\"\"\"\n",
        "  SELECT YEAR(Date) AS Year, MONTH(Date) AS Month, SUM(Volume) AS TotalVolume\n",
        "  FROM aapl_csv\n",
        "  GROUP BY YEAR(Date), MONTH(Date)\n",
        "  ORDER BY YEAR(Date), MONTH(Date)\n",
        "\"\"\")\n",
        "query5.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SYKnCMGqtdl2",
        "outputId": "cb936efb-7204-427d-953b-0fa40cce3942"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----------+\n",
            "|Year|Month|TotalVolume|\n",
            "+----+-----+-----------+\n",
            "|2014|    9|  142718700|\n",
            "|2014|   10| 1217561500|\n",
            "|2014|   11|  820408200|\n",
            "|2014|   12| 1126799200|\n",
            "|2015|    1| 1251439200|\n",
            "|2015|    2| 1136535200|\n",
            "|2015|    3| 1211483600|\n",
            "|2015|    4|  981806600|\n",
            "|2015|    5|  895639500|\n",
            "|2015|    6|  935962400|\n",
            "|2015|    7| 1000057400|\n",
            "|2015|    8| 1847943200|\n",
            "|2015|    9| 1086531300|\n",
            "|2015|   10|  990374200|\n",
            "|2015|   11|  918226100|\n",
            "|2015|   12|  753944200|\n",
            "|2016|    1| 1271024100|\n",
            "|2016|    2|  977450100|\n",
            "|2016|    3|  605336100|\n",
            "|2016|    4|  846522200|\n",
            "+----+-----+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcul de la moyenne mobile sur 10 jours"
      ],
      "metadata": {
        "id": "UxVweu2ptlAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Calculer la moyenne mobile sur 10 jours\n",
        "windowSpec = Window.orderBy(\"Date\").rowsBetween(-9, 0)\n",
        "aaplStockDataWithMovingAverage = aaplStockData \\\n",
        "    .withColumn(\"10_day_MA\", avg(\"Close\").over(windowSpec))\n",
        "\n",
        "# Montrer les 20 premiers résultats\n",
        "aaplStockDataWithMovingAverage.select(\"Date\", \"Close\", \"10_day_MA\").show(20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MFlhWIEftm_O",
        "outputId": "e9297fe8-aff2-4dec-e3d5-37a62c7f8973"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+------------------+\n",
            "|               Date|     Close|         10_day_MA|\n",
            "+-------------------+----------+------------------+\n",
            "|2014-09-29 00:00:00| 99.620003|         99.620003|\n",
            "|2014-10-06 00:00:00|100.730003|        100.175003|\n",
            "|2014-10-13 00:00:00| 97.669998| 99.34000133333335|\n",
            "|2014-10-20 00:00:00|105.220001|      100.81000125|\n",
            "|2014-10-27 00:00:00|     108.0|        102.248001|\n",
            "|2014-11-03 00:00:00|109.010002|103.37500116666666|\n",
            "|2014-11-10 00:00:00|    114.18|104.91857242857142|\n",
            "|2014-11-17 00:00:00|116.470001|        106.362501|\n",
            "|2014-11-24 00:00:00|    118.93|107.75888977777777|\n",
            "|2014-12-01 00:00:00|     115.0|108.48300079999999|\n",
            "|2014-12-08 00:00:00|109.730003|109.49400079999998|\n",
            "|2014-12-15 00:00:00|111.779999|       110.5990004|\n",
            "|2014-12-22 00:00:00|113.989998|       112.2310004|\n",
            "|2014-12-29 00:00:00|109.330002|       112.6420005|\n",
            "|2015-01-05 00:00:00|112.010002|113.04300070000002|\n",
            "|2015-01-12 00:00:00|105.989998|       112.7410003|\n",
            "|2015-01-19 00:00:00|112.980003|       112.6210006|\n",
            "|2015-01-26 00:00:00|117.160004|112.69000090000002|\n",
            "|2015-02-02 00:00:00|    118.93|       112.6900009|\n",
            "|2015-02-09 00:00:00|127.080002|113.89800109999999|\n",
            "+-------------------+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}